\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{dettmers2022llmint8}
\citation{dettmers2023qlora}
\citation{frantar2022gptq}
\citation{lin2023awq}
\citation{dettmers2022llmint8}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:introduction}{{1}{1}{Introduction}{section.1}{}}
\newlabel{sec:introduction@cref}{{[section][1][]1}{[1][1][]1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Design Choices}{1}{section.2}\protected@file@percent }
\newlabel{sec:design}{{2}{1}{Design Choices}{section.2}{}}
\newlabel{sec:design@cref}{{[section][2][]2}{[1][1][]1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Infrastructure: Modal Serverless GPUs}{1}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Quantization Library: BitsAndBytes}{1}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Why Not 8-bit Quantization}{1}{subsection.2.3}\protected@file@percent }
\citation{llama32}
\citation{reddy2019coqa}
\citation{dettmers2023qlora}
\citation{eval2023harness}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Code Architecture}{2}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Experimental Setup}{2}{section.3}\protected@file@percent }
\newlabel{sec:methods}{{3}{2}{Experimental Setup}{section.3}{}}
\newlabel{sec:methods@cref}{{[section][3][]3}{[1][2][]2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Model and Dataset}{2}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Quantization Configurations}{2}{subsection.3.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Quantization results on CoQA (n=50, zero-shot)}}{2}{table.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:main_results}{{1}{2}{Quantization results on CoQA (n=50, zero-shot)}{table.caption.2}{}}
\newlabel{tab:main_results@cref}{{[table][1][]1}{[1][2][]2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Evaluation Protocol}{2}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Hardware}{2}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Metrics}{2}{subsection.3.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{2}{section.4}\protected@file@percent }
\newlabel{sec:results}{{4}{2}{Results}{section.4}{}}
\newlabel{sec:results@cref}{{[section][4][]4}{[1][2][]2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Accuracy and Memory}{2}{subsection.4.1}\protected@file@percent }
\citation{nagel2021white}
\citation{gholami2022survey}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces NF4 vs FP4 comparison. Both require identical memory; NF4 achieves substantially higher accuracy while exceeding the FP16 baseline.}}{3}{figure.caption.3}\protected@file@percent }
\newlabel{fig:nf4_fp4}{{1}{3}{NF4 vs FP4 comparison. Both require identical memory; NF4 achieves substantially higher accuracy while exceeding the FP16 baseline}{figure.caption.3}{}}
\newlabel{fig:nf4_fp4@cref}{{[figure][1][]1}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Performance Tradeoffs}{3}{subsection.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Inference performance on NVIDIA A100-40GB}}{3}{table.caption.4}\protected@file@percent }
\newlabel{tab:perf}{{2}{3}{Inference performance on NVIDIA A100-40GB}{table.caption.4}{}}
\newlabel{tab:perf@cref}{{[table][2][]2}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Accuracy vs Memory Visualization}{3}{subsection.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Accuracy vs memory tradeoff. NF4 achieves highest F1 at lowest memory, strictly dominating both FP4 and FP16.}}{3}{figure.caption.5}\protected@file@percent }
\newlabel{fig:tradeoff}{{2}{3}{Accuracy vs memory tradeoff. NF4 achieves highest F1 at lowest memory, strictly dominating both FP4 and FP16}{figure.caption.5}{}}
\newlabel{fig:tradeoff@cref}{{[figure][2][]2}{[1][3][]3}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{3}{section.5}\protected@file@percent }
\newlabel{sec:discussion}{{5}{3}{Discussion}{section.5}{}}
\newlabel{sec:discussion@cref}{{[section][5][]5}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Why NF4 Outperforms FP4}{3}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Practical Recommendations}{3}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Limitations}{4}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Future Work}{4}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{4}{section.6}\protected@file@percent }
\newlabel{sec:conclusion}{{6}{4}{Conclusion}{section.6}{}}
\newlabel{sec:conclusion@cref}{{[section][6][]6}{[1][4][]4}}
\bibstyle{plain}
\bibdata{references}
\bibcite{dao2022flashattention}{1}
\bibcite{dettmers2022llmint8}{2}
\bibcite{dettmers2023qlora}{3}
\bibcite{frantar2022gptq}{4}
\bibcite{eval2023harness}{5}
\bibcite{gholami2022survey}{6}
\bibcite{jacob2018quantization}{7}
\bibcite{kaplan2020scaling}{8}
\bibcite{lin2023awq}{9}
\bibcite{llama32}{10}
\bibcite{nagel2021white}{11}
\bibcite{rajpurkar2016squad}{12}
\bibcite{reddy2019coqa}{13}
\bibcite{shazeer2019fast}{14}
\bibcite{touvron2023llama}{15}
\bibcite{touvron2023llama2}{16}
\bibcite{vaswani2017attention}{17}
\bibcite{xiao2023smoothquant}{18}
\bibcite{zhu2023survey}{19}
\gdef \@abspage@last{6}
